{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====================================================================================================================\n",
    "# **Tesla News Sentiment Stock Prediction**\n",
    "\n",
    "We have developed an innovative application designed to forecast the performance of various electric vehicle (EV) manufacturing stocks. Leveraging advanced sentiment analysis algorithms, our application extracts valuable insights from news articles pertaining to Tesla, a leading player in the EV industry. By analyzing the sentiment expressed in these articles, our application generates predictive models capable of forecasting the market data of EV stocks. This cutting-edge approach not only enables investors to make informed decisions but also provides a comprehensive understanding of the market dynamics influenced by Tesla's activities and perceptions.\n",
    "\n",
    "Team Member:\n",
    "\n",
    "1. M. Gifhari Heryndra (Data Analyst)\n",
    "2. Fadhil Athallah (Data Scientist)\n",
    "3. Reski Hidayat (Data Engineer)\n",
    "\n",
    "====================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.** **Import Libraries** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.** **Data Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ```tweet_cleaned.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>tweet_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>tesla open new megafactory shanghai china comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>china hold military drill around taiwan ftx co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>watch tesla chief executive elon musk making p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>tesla model x starting show age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>market biggest company apple tesla microsoft i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22340</th>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>plane owned tesla engineer crash 3 dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22341</th>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>plane owned tesla engineer crash 3 dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22342</th>\n",
       "      <td>2010-01-14</td>\n",
       "      <td>move thomas edison nikola tesla pioneer altern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22343</th>\n",
       "      <td>2009-09-15</td>\n",
       "      <td>bloomberg news electric sportscar maker tesla ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22344</th>\n",
       "      <td>2008-07-08</td>\n",
       "      <td>tesla tap chrysler executive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22345 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                                    tweet_processed\n",
       "0      2023-04-10  tesla open new megafactory shanghai china comp...\n",
       "1      2023-04-10  china hold military drill around taiwan ftx co...\n",
       "2      2023-04-09  watch tesla chief executive elon musk making p...\n",
       "3      2023-04-09                    tesla model x starting show age\n",
       "4      2023-04-09  market biggest company apple tesla microsoft i...\n",
       "...           ...                                                ...\n",
       "22340  2010-02-17            plane owned tesla engineer crash 3 dead\n",
       "22341  2010-02-17            plane owned tesla engineer crash 3 dead\n",
       "22342  2010-01-14  move thomas edison nikola tesla pioneer altern...\n",
       "22343  2009-09-15  bloomberg news electric sportscar maker tesla ...\n",
       "22344  2008-07-08                       tesla tap chrysler executive\n",
       "\n",
       "[22345 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet=pd.read_csv('tweets_cleaned.csv')\n",
    "Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column for the dataset, the column contain news count and all of sentiment score\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code effectively aggregates tweets by date, providing a consolidated view of tweet data for analysis or further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate titles and count news\n",
    "Tweet['tweet_processed'] = Tweet.groupby('Date')['tweet_processed'].transform(lambda x: ' '.join(x))\n",
    "Tweet['news_count'] = Tweet.groupby('Date')['tweet_processed'].transform('count')\n",
    "Tweet = Tweet.drop_duplicates(subset=['Date', 'tweet_processed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed by the use of VADER sentiment analyzer to add sentiment score from the tweet title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate sentiment\n",
    "def analyze_sentiment(text):\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "# Apply sentiment analysis to each concatenated title\n",
    "Tweet['sentiment'] = Tweet['tweet_processed'].apply(analyze_sentiment)\n",
    "\n",
    "# Extract sentiment scores\n",
    "Tweet['positive'] = Tweet['sentiment'].apply(lambda x: x['pos'])\n",
    "Tweet['negative'] = Tweet['sentiment'].apply(lambda x: x['neg'])\n",
    "Tweet['neutral'] = Tweet['sentiment'].apply(lambda x: x['neu'])\n",
    "Tweet['compound'] = Tweet['sentiment'].apply(lambda x: x['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Function to categorize sentiment\n",
    "def categorize_sentiment(compound_score):\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis to each concatenated title\n",
    "Tweet['sentiment'] = Tweet['tweet_processed'].apply(lambda x: sia.polarity_scores(x))\n",
    "Tweet['sentiment_category'] = Tweet['compound'].apply(categorize_sentiment)\n",
    "Tweet['Date']=pd.to_datetime(Tweet['Date'],utc=True).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the CSV of `STOCK`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Company_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Next Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>NIO</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>66849000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>11.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>NIO</td>\n",
       "      <td>6.620000</td>\n",
       "      <td>12.690000</td>\n",
       "      <td>6.520000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>158346500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>9.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>NIO</td>\n",
       "      <td>12.660000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>9.220000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>172473600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-17</td>\n",
       "      <td>NIO</td>\n",
       "      <td>9.610000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>56323900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>7.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>NIO</td>\n",
       "      <td>8.730000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>7.670000</td>\n",
       "      <td>7.680000</td>\n",
       "      <td>41827600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.680000</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12046</th>\n",
       "      <td>12046</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>195.580002</td>\n",
       "      <td>197.330002</td>\n",
       "      <td>194.419998</td>\n",
       "      <td>195.279999</td>\n",
       "      <td>110252200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.279999</td>\n",
       "      <td>207.460007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12047</th>\n",
       "      <td>12047</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>197.529999</td>\n",
       "      <td>207.789993</td>\n",
       "      <td>197.199997</td>\n",
       "      <td>207.460007</td>\n",
       "      <td>170222100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.460007</td>\n",
       "      <td>194.770004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12048</th>\n",
       "      <td>12048</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>199.910004</td>\n",
       "      <td>202.690002</td>\n",
       "      <td>192.199997</td>\n",
       "      <td>194.770004</td>\n",
       "      <td>169545900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.770004</td>\n",
       "      <td>192.580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12049</th>\n",
       "      <td>12049</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>197.320007</td>\n",
       "      <td>198.740005</td>\n",
       "      <td>190.320007</td>\n",
       "      <td>192.580002</td>\n",
       "      <td>126463800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.580002</td>\n",
       "      <td>185.520004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12050</th>\n",
       "      <td>12050</td>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>190.520004</td>\n",
       "      <td>190.679993</td>\n",
       "      <td>183.759995</td>\n",
       "      <td>185.520004</td>\n",
       "      <td>133882500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.520004</td>\n",
       "      <td>185.059998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12051 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        Date Company_ID        Open        High         Low  \\\n",
       "0          0  2018-09-12        NIO    6.000000    6.930000    5.350000   \n",
       "1          1  2018-09-13        NIO    6.620000   12.690000    6.520000   \n",
       "2          2  2018-09-14        NIO   12.660000   13.800000    9.220000   \n",
       "3          3  2018-09-17        NIO    9.610000    9.750000    8.500000   \n",
       "4          4  2018-09-18        NIO    8.730000    9.100000    7.670000   \n",
       "...      ...         ...        ...         ...         ...         ...   \n",
       "12046  12046  2023-03-30       TSLA  195.580002  197.330002  194.419998   \n",
       "12047  12047  2023-03-31       TSLA  197.529999  207.789993  197.199997   \n",
       "12048  12048  2023-04-03       TSLA  199.910004  202.690002  192.199997   \n",
       "12049  12049  2023-04-04       TSLA  197.320007  198.740005  190.320007   \n",
       "12050  12050  2023-04-05       TSLA  190.520004  190.679993  183.759995   \n",
       "\n",
       "            Close     Volume  Dividends  Stock Splits   Adj Close  Next Close  \n",
       "0        6.600000   66849000        0.0           0.0    6.600000   11.600000  \n",
       "1       11.600000  158346500        0.0           0.0   11.600000    9.900000  \n",
       "2        9.900000  172473600        0.0           0.0    9.900000    8.500000  \n",
       "3        8.500000   56323900        0.0           0.0    8.500000    7.680000  \n",
       "4        7.680000   41827600        0.0           0.0    7.680000    8.500000  \n",
       "...           ...        ...        ...           ...         ...         ...  \n",
       "12046  195.279999  110252200        0.0           0.0  195.279999  207.460007  \n",
       "12047  207.460007  170222100        0.0           0.0  207.460007  194.770004  \n",
       "12048  194.770004  169545900        0.0           0.0  194.770004  192.580002  \n",
       "12049  192.580002  126463800        0.0           0.0  192.580002  185.520004  \n",
       "12050  185.520004  133882500        0.0           0.0  185.520004  185.059998  \n",
       "\n",
       "[12051 rows x 12 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = pd.read_csv('merged_data.csv')\n",
    "stock.reset_index(inplace=True)\n",
    "stock['Next Close'] = stock['Close'].shift(-1)\n",
    "stock.dropna(inplace=True)\n",
    "stock['Date'] = pd.to_datetime(stock['Date'], utc=True).dt.date\n",
    "stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the `stock` and `tweet` csv by its date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Company_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Next Close</th>\n",
       "      <th>tweet_processed</th>\n",
       "      <th>news_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>5122</td>\n",
       "      <td>2008-07-08</td>\n",
       "      <td>PCRFY</td>\n",
       "      <td>16.691616</td>\n",
       "      <td>16.867801</td>\n",
       "      <td>16.599693</td>\n",
       "      <td>16.852480</td>\n",
       "      <td>349094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.852480</td>\n",
       "      <td>16.201361</td>\n",
       "      <td>tesla tap chrysler executive</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535</th>\n",
       "      <td>1279</td>\n",
       "      <td>2008-07-08</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2.793185</td>\n",
       "      <td>2.861983</td>\n",
       "      <td>2.706042</td>\n",
       "      <td>2.758786</td>\n",
       "      <td>180528800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.758786</td>\n",
       "      <td>2.710628</td>\n",
       "      <td>tesla tap chrysler executive</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>1579</td>\n",
       "      <td>2009-09-15</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>3.715074</td>\n",
       "      <td>3.802217</td>\n",
       "      <td>3.680675</td>\n",
       "      <td>3.756352</td>\n",
       "      <td>54613600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.756352</td>\n",
       "      <td>3.655448</td>\n",
       "      <td>bloomberg news electric sportscar maker tesla ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>5422</td>\n",
       "      <td>2009-09-15</td>\n",
       "      <td>PCRFY</td>\n",
       "      <td>11.990054</td>\n",
       "      <td>12.075420</td>\n",
       "      <td>11.912449</td>\n",
       "      <td>12.036617</td>\n",
       "      <td>190405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.036617</td>\n",
       "      <td>12.090944</td>\n",
       "      <td>bloomberg news electric sportscar maker tesla ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540</th>\n",
       "      <td>5506</td>\n",
       "      <td>2010-01-14</td>\n",
       "      <td>PCRFY</td>\n",
       "      <td>13.099814</td>\n",
       "      <td>13.309350</td>\n",
       "      <td>13.014449</td>\n",
       "      <td>13.231744</td>\n",
       "      <td>842698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.231744</td>\n",
       "      <td>13.138618</td>\n",
       "      <td>move thomas edison nikola tesla pioneer altern...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.14, 'neu': 0.698, 'pos': 0.163, 'com...</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>8834</td>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>PCRFY</td>\n",
       "      <td>9.235722</td>\n",
       "      <td>9.285217</td>\n",
       "      <td>9.215925</td>\n",
       "      <td>9.255521</td>\n",
       "      <td>216544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.255521</td>\n",
       "      <td>9.005571</td>\n",
       "      <td>tesla sprawling manufacturing hub austin texas...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'neg': 0.121, 'neu': 0.752, 'pos': 0.127, 'co...</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>12050</td>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>190.520004</td>\n",
       "      <td>190.679993</td>\n",
       "      <td>183.759995</td>\n",
       "      <td>185.520004</td>\n",
       "      <td>133882500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.520004</td>\n",
       "      <td>185.059998</td>\n",
       "      <td>tesla sprawling manufacturing hub austin texas...</td>\n",
       "      <td>5</td>\n",
       "      <td>{'neg': 0.121, 'neu': 0.752, 'pos': 0.127, 'co...</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>1149</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>NIO</td>\n",
       "      <td>8.940000</td>\n",
       "      <td>9.070000</td>\n",
       "      <td>8.830000</td>\n",
       "      <td>9.010000</td>\n",
       "      <td>23019800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.010000</td>\n",
       "      <td>7.570035</td>\n",
       "      <td>link correction tesla employee privately share...</td>\n",
       "      <td>13</td>\n",
       "      <td>{'neg': 0.034, 'neu': 0.844, 'pos': 0.122, 'co...</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>4992</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>265.754749</td>\n",
       "      <td>270.713149</td>\n",
       "      <td>264.185245</td>\n",
       "      <td>270.283295</td>\n",
       "      <td>39765400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.283295</td>\n",
       "      <td>15.495338</td>\n",
       "      <td>link correction tesla employee privately share...</td>\n",
       "      <td>13</td>\n",
       "      <td>{'neg': 0.034, 'neu': 0.844, 'pos': 0.122, 'co...</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>8835</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>PCRFY</td>\n",
       "      <td>8.998147</td>\n",
       "      <td>9.116935</td>\n",
       "      <td>8.958651</td>\n",
       "      <td>9.005571</td>\n",
       "      <td>101765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.005571</td>\n",
       "      <td>1.592667</td>\n",
       "      <td>link correction tesla employee privately share...</td>\n",
       "      <td>13</td>\n",
       "      <td>{'neg': 0.034, 'neu': 0.844, 'pos': 0.122, 'co...</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7468 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        Date Company_ID        Open        High         Low  \\\n",
       "4536   5122  2008-07-08      PCRFY   16.691616   16.867801   16.599693   \n",
       "4535   1279  2008-07-08       NVDA    2.793185    2.861983    2.706042   \n",
       "4537   1579  2009-09-15       NVDA    3.715074    3.802217    3.680675   \n",
       "4538   5422  2009-09-15      PCRFY   11.990054   12.075420   11.912449   \n",
       "4540   5506  2010-01-14      PCRFY   13.099814   13.309350   13.014449   \n",
       "...     ...         ...        ...         ...         ...         ...   \n",
       "4530   8834  2023-04-05      PCRFY    9.235722    9.285217    9.215925   \n",
       "4531  12050  2023-04-05       TSLA  190.520004  190.679993  183.759995   \n",
       "4532   1149  2023-04-06        NIO    8.940000    9.070000    8.830000   \n",
       "4533   4992  2023-04-06       NVDA  265.754749  270.713149  264.185245   \n",
       "4534   8835  2023-04-06      PCRFY    8.998147    9.116935    8.958651   \n",
       "\n",
       "           Close     Volume  Dividends  Stock Splits   Adj Close  Next Close  \\\n",
       "4536   16.852480     349094        0.0           0.0   16.852480   16.201361   \n",
       "4535    2.758786  180528800        0.0           0.0    2.758786    2.710628   \n",
       "4537    3.756352   54613600        0.0           0.0    3.756352    3.655448   \n",
       "4538   12.036617     190405        0.0           0.0   12.036617   12.090944   \n",
       "4540   13.231744     842698        0.0           0.0   13.231744   13.138618   \n",
       "...          ...        ...        ...           ...         ...         ...   \n",
       "4530    9.255521     216544        0.0           0.0    9.255521    9.005571   \n",
       "4531  185.520004  133882500        0.0           0.0  185.520004  185.059998   \n",
       "4532    9.010000   23019800        0.0           0.0    9.010000    7.570035   \n",
       "4533  270.283295   39765400        0.0           0.0  270.283295   15.495338   \n",
       "4534    9.005571     101765        0.0           0.0    9.005571    1.592667   \n",
       "\n",
       "                                        tweet_processed  news_count  \\\n",
       "4536                       tesla tap chrysler executive           1   \n",
       "4535                       tesla tap chrysler executive           1   \n",
       "4537  bloomberg news electric sportscar maker tesla ...           1   \n",
       "4538  bloomberg news electric sportscar maker tesla ...           1   \n",
       "4540  move thomas edison nikola tesla pioneer altern...           1   \n",
       "...                                                 ...         ...   \n",
       "4530  tesla sprawling manufacturing hub austin texas...           5   \n",
       "4531  tesla sprawling manufacturing hub austin texas...           5   \n",
       "4532  link correction tesla employee privately share...          13   \n",
       "4533  link correction tesla employee privately share...          13   \n",
       "4534  link correction tesla employee privately share...          13   \n",
       "\n",
       "                                              sentiment  positive  negative  \\\n",
       "4536  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...     0.000     0.000   \n",
       "4535  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...     0.000     0.000   \n",
       "4537  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...     0.000     0.000   \n",
       "4538  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...     0.000     0.000   \n",
       "4540  {'neg': 0.14, 'neu': 0.698, 'pos': 0.163, 'com...     0.163     0.140   \n",
       "...                                                 ...       ...       ...   \n",
       "4530  {'neg': 0.121, 'neu': 0.752, 'pos': 0.127, 'co...     0.127     0.121   \n",
       "4531  {'neg': 0.121, 'neu': 0.752, 'pos': 0.127, 'co...     0.127     0.121   \n",
       "4532  {'neg': 0.034, 'neu': 0.844, 'pos': 0.122, 'co...     0.122     0.034   \n",
       "4533  {'neg': 0.034, 'neu': 0.844, 'pos': 0.122, 'co...     0.122     0.034   \n",
       "4534  {'neg': 0.034, 'neu': 0.844, 'pos': 0.122, 'co...     0.122     0.034   \n",
       "\n",
       "      neutral  compound sentiment_category  \n",
       "4536    1.000    0.0000            Neutral  \n",
       "4535    1.000    0.0000            Neutral  \n",
       "4537    1.000    0.0000            Neutral  \n",
       "4538    1.000    0.0000            Neutral  \n",
       "4540    0.698    0.0772           Positive  \n",
       "...       ...       ...                ...  \n",
       "4530    0.752    0.0772           Positive  \n",
       "4531    0.752    0.0772           Positive  \n",
       "4532    0.844    0.9201           Positive  \n",
       "4533    0.844    0.9201           Positive  \n",
       "4534    0.844    0.9201           Positive  \n",
       "\n",
       "[7468 rows x 20 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge tweets data with stock data on 'Date'\n",
    "merged_data = pd.merge(stock, Tweet, on='Date', how='inner')\n",
    "\n",
    "# Sort by date\n",
    "merged_data = merged_data.sort_values(by='Date')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the unused column from the dataset based on domain knowledge and its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Next Close</th>\n",
       "      <th>news_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>PCRFY</td>\n",
       "      <td>16.691616</td>\n",
       "      <td>16.867801</td>\n",
       "      <td>16.599693</td>\n",
       "      <td>16.852480</td>\n",
       "      <td>349094</td>\n",
       "      <td>16.201361</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2.793185</td>\n",
       "      <td>2.861983</td>\n",
       "      <td>2.706042</td>\n",
       "      <td>2.758786</td>\n",
       "      <td>180528800</td>\n",
       "      <td>2.710628</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>3.715074</td>\n",
       "      <td>3.802217</td>\n",
       "      <td>3.680675</td>\n",
       "      <td>3.756352</td>\n",
       "      <td>54613600</td>\n",
       "      <td>3.655448</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>PCRFY</td>\n",
       "      <td>11.990054</td>\n",
       "      <td>12.075420</td>\n",
       "      <td>11.912449</td>\n",
       "      <td>12.036617</td>\n",
       "      <td>190405</td>\n",
       "      <td>12.090944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540</th>\n",
       "      <td>PCRFY</td>\n",
       "      <td>13.099814</td>\n",
       "      <td>13.309350</td>\n",
       "      <td>13.014449</td>\n",
       "      <td>13.231744</td>\n",
       "      <td>842698</td>\n",
       "      <td>13.138618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>PCRFY</td>\n",
       "      <td>9.235722</td>\n",
       "      <td>9.285217</td>\n",
       "      <td>9.215925</td>\n",
       "      <td>9.255521</td>\n",
       "      <td>216544</td>\n",
       "      <td>9.005571</td>\n",
       "      <td>5</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>190.520004</td>\n",
       "      <td>190.679993</td>\n",
       "      <td>183.759995</td>\n",
       "      <td>185.520004</td>\n",
       "      <td>133882500</td>\n",
       "      <td>185.059998</td>\n",
       "      <td>5</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>NIO</td>\n",
       "      <td>8.940000</td>\n",
       "      <td>9.070000</td>\n",
       "      <td>8.830000</td>\n",
       "      <td>9.010000</td>\n",
       "      <td>23019800</td>\n",
       "      <td>7.570035</td>\n",
       "      <td>13</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>265.754749</td>\n",
       "      <td>270.713149</td>\n",
       "      <td>264.185245</td>\n",
       "      <td>270.283295</td>\n",
       "      <td>39765400</td>\n",
       "      <td>15.495338</td>\n",
       "      <td>13</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>PCRFY</td>\n",
       "      <td>8.998147</td>\n",
       "      <td>9.116935</td>\n",
       "      <td>8.958651</td>\n",
       "      <td>9.005571</td>\n",
       "      <td>101765</td>\n",
       "      <td>1.592667</td>\n",
       "      <td>13</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7468 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company_ID        Open        High         Low       Close     Volume  \\\n",
       "4536      PCRFY   16.691616   16.867801   16.599693   16.852480     349094   \n",
       "4535       NVDA    2.793185    2.861983    2.706042    2.758786  180528800   \n",
       "4537       NVDA    3.715074    3.802217    3.680675    3.756352   54613600   \n",
       "4538      PCRFY   11.990054   12.075420   11.912449   12.036617     190405   \n",
       "4540      PCRFY   13.099814   13.309350   13.014449   13.231744     842698   \n",
       "...         ...         ...         ...         ...         ...        ...   \n",
       "4530      PCRFY    9.235722    9.285217    9.215925    9.255521     216544   \n",
       "4531       TSLA  190.520004  190.679993  183.759995  185.520004  133882500   \n",
       "4532        NIO    8.940000    9.070000    8.830000    9.010000   23019800   \n",
       "4533       NVDA  265.754749  270.713149  264.185245  270.283295   39765400   \n",
       "4534      PCRFY    8.998147    9.116935    8.958651    9.005571     101765   \n",
       "\n",
       "      Next Close  news_count  positive  negative  neutral  compound  \\\n",
       "4536   16.201361           1     0.000     0.000    1.000    0.0000   \n",
       "4535    2.710628           1     0.000     0.000    1.000    0.0000   \n",
       "4537    3.655448           1     0.000     0.000    1.000    0.0000   \n",
       "4538   12.090944           1     0.000     0.000    1.000    0.0000   \n",
       "4540   13.138618           1     0.163     0.140    0.698    0.0772   \n",
       "...          ...         ...       ...       ...      ...       ...   \n",
       "4530    9.005571           5     0.127     0.121    0.752    0.0772   \n",
       "4531  185.059998           5     0.127     0.121    0.752    0.0772   \n",
       "4532    7.570035          13     0.122     0.034    0.844    0.9201   \n",
       "4533   15.495338          13     0.122     0.034    0.844    0.9201   \n",
       "4534    1.592667          13     0.122     0.034    0.844    0.9201   \n",
       "\n",
       "     sentiment_category  \n",
       "4536            Neutral  \n",
       "4535            Neutral  \n",
       "4537            Neutral  \n",
       "4538            Neutral  \n",
       "4540           Positive  \n",
       "...                 ...  \n",
       "4530           Positive  \n",
       "4531           Positive  \n",
       "4532           Positive  \n",
       "4533           Positive  \n",
       "4534           Positive  \n",
       "\n",
       "[7468 rows x 13 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = merged_data.drop(columns=['Date','index', 'sentiment','tweet_processed','Dividends','Stock Splits','Adj Close'])\n",
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final dataset that we can use for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3.** **Modeling**\n",
    "For modeling, we will try four different regression algorithms to compare and select the best one based on its `R2` and `RMSE` scores. The algorithms include `Linear Regression`, `XGBoost`, `Random Forest`, and `SVR`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "final_data = merged_data.dropna()\n",
    "\n",
    "# Separate features and target\n",
    "X = final_data.drop(columns=['Next Close'])\n",
    "y = final_data['Next Close'].values\n",
    "\n",
    "# Define categorical features\n",
    "categorical_features = ['Company_ID', 'sentiment_category']\n",
    "\n",
    "# Define preprocessor with OneHotEncoder for categorical features and StandardScaler for numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), [col for col in X.columns if col not in categorical_features]),\n",
    "        ('cat', OneHotEncoder(categories='auto'), categorical_features)  \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear Regression** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 13.664077063408547\n",
      "Root Mean Squared Error (RMSE): 3.6964952405499654\n",
      "R^2 Score: 0.9977945352839853\n"
     ]
    }
   ],
   "source": [
    "# Define the model pipeline\n",
    "model_LinReg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_LinReg.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model_LinReg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 23.242072724584393\n",
      "Root Mean Squared Error (RMSE): 4.821003290248244\n",
      "R^2 Score: 0.9962485888301679\n"
     ]
    }
   ],
   "source": [
    "# Define the model pipeline with XGBoost\n",
    "model_XGB = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb.XGBRegressor())\n",
    "])\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_XGB.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_XGB.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 17.476215418576402\n",
      "Root Mean Squared Error (RMSE): 4.180456364869319\n",
      "R^2 Score: 0.9971792330871466\n"
     ]
    }
   ],
   "source": [
    "# Define the model pipeline with Random Forest\n",
    "model_RF = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_RF.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_RF.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 451.14040674618104\n",
      "Root Mean Squared Error (RMSE): 21.240066072076637\n",
      "R^2 Score: 0.927183208611163\n"
     ]
    }
   ],
   "source": [
    "# Define the model pipeline with SVR\n",
    "model_SVR = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', SVR())\n",
    "])\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the SVR model\n",
    "model_SVR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using SVR\n",
    "y_pred = model_SVR.predict(X_test)\n",
    "\n",
    "# Evaluate the SVR model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Best Model**\n",
    "Based on the RMSE score, Linear Regression emerges as the best model with an RMSE of only 3.69. To further improve its performance, we intend to fine-tune this model using grid search. Once optimized, we'll save it and incorporate it into the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__fit_intercept': True, 'model__positive': False}\n",
      "Mean Squared Error (MSE): 13.664077063408547\n",
      "Root Mean Squared Error (RMSE): 3.6964952405499654\n",
      "R^2 Score: 0.9977945352839853\n"
     ]
    }
   ],
   "source": [
    "# Define the model pipeline\n",
    "model_LinReg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__positive': [True, False]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(model_LinReg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_LinReg.pkl']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, 'model_LinReg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4.** **Model Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_ID</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Next Close</th>\n",
       "      <th>news_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>31.955640</td>\n",
       "      <td>37.103098</td>\n",
       "      <td>87.367544</td>\n",
       "      <td>91.940307</td>\n",
       "      <td>28540</td>\n",
       "      <td>98.804392</td>\n",
       "      <td>48</td>\n",
       "      <td>0.120125</td>\n",
       "      <td>0.159145</td>\n",
       "      <td>0.316411</td>\n",
       "      <td>-0.505889</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>81.900810</td>\n",
       "      <td>76.929805</td>\n",
       "      <td>65.695750</td>\n",
       "      <td>29.648140</td>\n",
       "      <td>82770</td>\n",
       "      <td>40.437696</td>\n",
       "      <td>25</td>\n",
       "      <td>0.774185</td>\n",
       "      <td>0.229554</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.820361</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCRFY</td>\n",
       "      <td>34.356343</td>\n",
       "      <td>44.217000</td>\n",
       "      <td>47.360117</td>\n",
       "      <td>83.588258</td>\n",
       "      <td>88565</td>\n",
       "      <td>84.477127</td>\n",
       "      <td>63</td>\n",
       "      <td>0.622942</td>\n",
       "      <td>0.036139</td>\n",
       "      <td>0.201703</td>\n",
       "      <td>-0.442476</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>56.816132</td>\n",
       "      <td>92.720520</td>\n",
       "      <td>29.989682</td>\n",
       "      <td>55.324113</td>\n",
       "      <td>41486</td>\n",
       "      <td>92.414447</td>\n",
       "      <td>100</td>\n",
       "      <td>0.387441</td>\n",
       "      <td>0.638307</td>\n",
       "      <td>0.041170</td>\n",
       "      <td>-0.994928</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>73.833979</td>\n",
       "      <td>38.101907</td>\n",
       "      <td>91.095349</td>\n",
       "      <td>85.818926</td>\n",
       "      <td>78765</td>\n",
       "      <td>13.888175</td>\n",
       "      <td>51</td>\n",
       "      <td>0.297852</td>\n",
       "      <td>0.499941</td>\n",
       "      <td>0.862836</td>\n",
       "      <td>0.536272</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_ID       Open       High        Low      Close  Volume  Next Close  \\\n",
       "0       TSLA  31.955640  37.103098  87.367544  91.940307   28540   98.804392   \n",
       "1       NVDA  81.900810  76.929805  65.695750  29.648140   82770   40.437696   \n",
       "2      PCRFY  34.356343  44.217000  47.360117  83.588258   88565   84.477127   \n",
       "3       TSLA  56.816132  92.720520  29.989682  55.324113   41486   92.414447   \n",
       "4       NVDA  73.833979  38.101907  91.095349  85.818926   78765   13.888175   \n",
       "\n",
       "   news_count  positive  negative   neutral  compound sentiment_category  \n",
       "0          48  0.120125  0.159145  0.316411 -0.505889           Negative  \n",
       "1          25  0.774185  0.229554  0.978182  0.820361           Positive  \n",
       "2          63  0.622942  0.036139  0.201703 -0.442476            Neutral  \n",
       "3         100  0.387441  0.638307  0.041170 -0.994928            Neutral  \n",
       "4          51  0.297852  0.499941  0.862836  0.536272            Neutral  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model_LinReg = joblib.load('model_LinReg.pkl')\n",
    "\n",
    "# Define lists to store generated data and predictions\n",
    "random_data_list = []\n",
    "predictions = []\n",
    "\n",
    "# Generate 5 random data points and predictions\n",
    "for _ in range(5):\n",
    "    # Define the random data for each data point\n",
    "    random_data = {\n",
    "        'Company_ID': random.choice(['NVDA', 'TSLA', 'NIO', 'PCRFY']),  # Random company ID\n",
    "        'Open': random.uniform(10, 100),  # Random open price\n",
    "        'High': random.uniform(10, 100),  # Random high price\n",
    "        'Low': random.uniform(10, 100),   # Random low price\n",
    "        'Close': random.uniform(10, 100), # Random close price\n",
    "        'Volume': random.randint(1000, 100000),  # Random volume\n",
    "        'Next Close': random.uniform(10, 100), # Actual next close from the dataset\n",
    "        'news_count': random.randint(1, 100),    # Random news count\n",
    "        'positive': random.uniform(0, 1),    # Random sentiment scores\n",
    "        'negative': random.uniform(0, 1),\n",
    "        'neutral': random.uniform(0, 1),\n",
    "        'compound': random.uniform(-1, 1),\n",
    "        'sentiment_category': random.choice(['Positive', 'Negative', 'Neutral'])  # Random sentiment category\n",
    "    }\n",
    "    # Append the random data to the list\n",
    "    random_data_list.append(random_data)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "random_df = pd.DataFrame(random_data_list)\n",
    "\n",
    "random_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Close Prices for 5 Random Data Points:\n",
      "Next Close for Random Case 1: -0.8285348643031369\n",
      "Next Close for Random Case 2: 252.63851346460362\n",
      "Next Close for Random Case 3: 45.20808613718755\n",
      "Next Close for Random Case 4: 73.06512828351129\n",
      "Next Close for Random Case 5: 221.6911907449757\n"
     ]
    }
   ],
   "source": [
    "# Extract features (X) for prediction\n",
    "X_random = random_df.drop(['Next Close'], axis=1)  # Drop 'Next Close' as it's not used for prediction\n",
    "\n",
    "# Make predictions\n",
    "predicted_next_close = model_LinReg.predict(X_random)\n",
    "\n",
    "print(\"Predicted Next Close Prices for 5 Random Data Points:\")\n",
    "for i, pred in enumerate(predicted_next_close):\n",
    "    print(f\"Next Close for Random Case {i+1}: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model can predict the next close, this model is ready for deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
